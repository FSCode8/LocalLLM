{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f2ebe93-4626-4315-af65-df14c1268d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d778c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'llama3.2:latest'\n",
    "\n",
    "SYSTEM_PROMPT = \"You are a highly intelligent, friendly, and helpful AI assistant. \" \\\n",
    "\"Your goal is to provide accurate, clear, and engaging responses tailored to the user's needs. \" \\\n",
    "\"Answer concisely but thoroughly, ensuring responses are informative and well-structured. \" \\\n",
    "\"Adapt your tone based on the user’s style—be professional when needed and casual when appropriate. \" \\\n",
    "\"Prioritize clarity, empathy, and usefulness. If you don’t know something, admit it rather than making assumptions. \" \\\n",
    "\"Be proactive in asking clarifying questions when necessary. Maintain a positive and respectful tone at all times.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "278db76c-a87a-452b-a6b7-114f442a2580",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AssistantOllama:\n",
    "    def __init__(self, model,system_prompt):\n",
    "        self.system_prompt = system_prompt\n",
    "        self.model = model\n",
    "        self.history = []\n",
    "\n",
    "    def chat(self, message, history=None): \n",
    "        print(history)\n",
    "        if self.history != []:\n",
    "            messages = [{\"role\": \"system\", \"content\": SYSTEM_PROMPT}] + self.history + [{\"role\": \"user\", \"content\": message}]\n",
    "        else:\n",
    "            messages = [{\"role\": \"system\", \"content\": SYSTEM_PROMPT}] + [{\"role\": \"user\", \"content\": message}]\n",
    "        \n",
    "        # Get response from Ollama\n",
    "        response = ollama.chat(model=self.model, messages=messages)\n",
    "        \n",
    "        # Append user message and assistant response\n",
    "        self.history.append({\"role\": \"user\", \"content\": message})\n",
    "        self.history.append({\"role\": \"assistant\", \"content\": response.message.content})\n",
    "        print(response.message.content)\n",
    "        return response.message.content\n",
    "\n",
    "    def stream(self, message, history=None):\n",
    "        print(history)\n",
    "        if self.history != []:\n",
    "            messages = [{\"role\": \"system\", \"content\": SYSTEM_PROMPT}] + self.history + [{\"role\": \"user\", \"content\": message}]\n",
    "        else:\n",
    "            messages = [{\"role\": \"system\", \"content\": SYSTEM_PROMPT}] + [{\"role\": \"user\", \"content\": message}]\n",
    "        \n",
    "        # Start the streaming response\n",
    "        stream = ollama.chat(\n",
    "            model=MODEL,\n",
    "            messages=messages,\n",
    "            stream=True  # Make sure stream parameter is set to True\n",
    "        )\n",
    "        \n",
    "        # Stream each chunk as it arrives\n",
    "        response = \"\"\n",
    "        for chunk in stream:\n",
    "            if 'message' in chunk and chunk['message'].get('content'):\n",
    "                new_text = chunk['message']['content']\n",
    "                response += new_text\n",
    "                yield response  # With Gradio streaming, we yield the full response each time\n",
    "                \n",
    "        # Append user message and full assistant response to history\n",
    "        self.history.append({\"role\": \"user\", \"content\": message})\n",
    "        self.history.append({\"role\": \"assistant\", \"content\": response})\n",
    "\n",
    "    def clear(self):\n",
    "        self.history = []\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63191f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = AssistantOllama(model='llama3.2:latest', system_prompt=SYSTEM_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90f2ba8d-e6e0-4c18-b809-636378767ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(assistant.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17dc1f0e-5c0d-498e-9e43-d414aae9f211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Gradio interface\n",
    "chat_ui = gr.Interface(\n",
    "    fn=assistant.chat,  # Function to process input\n",
    "    inputs=\"text\",      # User input type\n",
    "    outputs=\"text\",     # Output type\n",
    "    title=\"Simple Chatbot\"\n",
    ")\n",
    "\n",
    "# Launch the UI\n",
    "chat_ui.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b60dcad-527c-4ef7-a1d8-f8760d648cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Gradio interface\n",
    "with gr.Blocks(css=\"footer {visibility: hidden}\") as chatbot_interface:\n",
    "    gr.Markdown(\"# Simple Chatbot\")\n",
    "    gr.Markdown(\"Welcome! Type a message and press Enter to chat.\")\n",
    "    \n",
    "    chatbot = gr.Chatbot(height=400)\n",
    "    msg = gr.Textbox(placeholder=\"Type your message here...\", container=False)\n",
    "    clear = gr.Button(\"Clear conversation\")\n",
    "    \n",
    "    msg.submit(\n",
    "        assistant.chat,\n",
    "        [msg, chatbot],\n",
    "        [chatbot],\n",
    "        api_name=\"chat\"\n",
    "    ).then(\n",
    "        lambda: \"\",\n",
    "        None,\n",
    "        [msg],\n",
    "        queue=False\n",
    "    )\n",
    "    \n",
    "    clear.click(assistant.clear, None, chatbot)\n",
    "\n",
    "chatbot_interface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a15c2e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': 'test'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"It looks like you're testing the waters!\\n\\nIs there anything specific you'd like to talk about or ask? I'm here to help with any questions, provide information, or just have a friendly conversation. Let me know how I can assist you!\"},\n",
       " {'role': 'user', 'content': 'test 2'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"You're testing again!\\n\\nIt seems like you're just making sure everything is working smoothly. I appreciate the extra confirmation.\\n\\nIf you're ready to move on, feel free to ask me anything or start a new conversation. If not, we can keep playing around and see how far we can take it!\"},\n",
       " {'role': 'user', 'content': 'what is the capital of paris?'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"The capital of Paris is actually... Paris itself!\\n\\nParis is a city, not a country, so it doesn't have a traditional capital. The city is the capital of France, a country located in Europe.\\n\\nHowever, if you're asking about the administrative center of the Île-de-France region, which surrounds and includes the city of Paris, that would be Paris-la-Réunie (a small commune) or more commonly, La Défense. But keep in mind that these are not typical capital cities with a central government building.\\n\\nIf you're looking for information about another country's capital, feel free to ask, and I'll do my best to help!\"},\n",
       " {'role': 'user', 'content': 'more information'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'd be happy to provide more information about Paris and France.\\n\\n**Paris**\\n\\n* Population: approximately 2.1 million people within the city limits\\n* Known for its iconic landmarks such as the Eiffel Tower, Notre-Dame Cathedral, the Louvre Museum, and many more\\n* World-famous art scene, fashion capital, and culinary destination\\n* Rich history dating back to the Roman era, with numerous historical sites and museums\\n\\n**France**\\n\\n* Official language: French (also widely spoken in Quebec, Canada)\\n* Capital city: Paris (as we discussed earlier)\\n* Area: 643,801 km² (248,573 sq mi)\\n* Population: approximately 67 million people\\n* Major cities: Marseille, Lyon, Toulouse, Nice, Bordeaux\\n\\n**Cultural Significance**\\n\\nFrance is known for its cultural influences, including:\\n\\n* Art and Architecture: Impressionism, Surrealism, and Art Nouveau movements originated in France\\n* Literature: Famous authors like Victor Hugo, Gustave Flaubert, and Marcel Proust hail from France\\n* Cuisine: French cuisine is renowned worldwide for its sophistication and elegance (think Escargots, Coq au Vin, and Macarons!)\\n* Music: French musical traditions include jazz, classical music, and chanson\\n\\n**Interesting Facts**\\n\\n* The Eiffel Tower was originally intended to be a temporary structure but became an instant iconic symbol of Paris\\n* France is home to the world's largest number of UNESCO World Heritage sites (59)\\n* The Louvre Museum has a stunning collection of art from around the world, including the Mona Lisa\\n\\nIs there anything specific you'd like to know more about?\"},\n",
       " {'role': 'user', 'content': 'hello'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"Hello!\\n\\nIt's great to have you here. Is there something on your mind that you'd like to chat about, or are you just looking for a friendly conversation?\\n\\nIf you need help with something or have a question, feel free to ask me anything. I'm all ears (or rather, all text).\\n\\nWe can talk about anything from art and culture to science and technology, or even share some fun facts and jokes.\\n\\nWhat's on your mind today?\"}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'user', 'metadata': None, 'content': 'more information', 'options': None}, {'role': 'assistant', 'metadata': None, 'content': \"I'd be happy to provide more information about Paris and France.\\n\\n**Paris**\\n\\n* Population: approximately 2.1 million people within the city limits\\n* Known for its iconic landmarks such as the Eiffel Tower, Notre-Dame Cathedral, the Louvre Museum, and many more\\n* World-famous art scene, fashion capital, and culinary destination\\n* Rich history dating back to the Roman era, with numerous historical sites and museums\\n\\n**France**\\n\\n* Official language: French (also widely spoken in Quebec, Canada)\\n* Capital city: Paris (as we discussed earlier)\\n* Area: 643,801 km² (248,573 sq mi)\\n* Population: approximately 67 million people\\n* Major cities: Marseille, Lyon, Toulouse, Nice, Bordeaux\\n\\n**Cultural Significance**\\n\\nFrance is known for its cultural influences, including:\\n\\n* Art and Architecture: Impressionism, Surrealism, and Art Nouveau movements originated in France\\n* Literature: Famous authors like Victor Hugo, Gustave Flaubert, and Marcel Proust hail from France\\n* Cuisine: French cuisine is renowned worldwide for its sophistication and elegance (think Escargots, Coq au Vin, and Macarons!)\\n* Music: French musical traditions include jazz, classical music, and chanson\\n\\n**Interesting Facts**\\n\\n* The Eiffel Tower was originally intended to be a temporary structure but became an instant iconic symbol of Paris\\n* France is home to the world's largest number of UNESCO World Heritage sites (59)\\n* The Louvre Museum has a stunning collection of art from around the world, including the Mona Lisa\\n\\nIs there anything specific you'd like to know more about?\", 'options': None}]\n",
      "Hello!\n",
      "\n",
      "It's great to see you again! How have you been today?\n",
      "\n",
      "We can pick up right where we left off, or start fresh. What would you like to talk about this time around?\n",
      "\n",
      "If you're feeling stuck, I can always suggest some conversation topics. We could:\n",
      "\n",
      "* Explore a new topic together (e.g., science, history, or entertainment)\n",
      "* Chat about your interests and hobbies\n",
      "* Play a fun game or activity\n",
      "\n",
      "Let me know what sounds good to you!\n"
     ]
    }
   ],
   "source": [
    "assistant.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c629226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    chat = gr.ChatInterface(assistant.stream, type=\"messages\")\n",
    "    clear_button = gr.Button(\"Clear Chat\")\n",
    "\n",
    "    # When the button is clicked, clear chat and run extra function\n",
    "    clear_button.click(lambda: ([], assistant.clear()), outputs=chat)\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22336974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "It looks like you're testing the waters!\n",
      "\n",
      "Is there anything specific you'd like to talk about or ask? I'm here to help with any questions, provide information, or just have a friendly conversation. Let me know how I can assist you!\n"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(fn=assistant.chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b7be502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7864\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[{'role': 'user', 'metadata': None, 'content': 'test', 'options': None}, {'role': 'assistant', 'metadata': None, 'content': \"It looks like you're testing to see how I respond! Don't worry, I'm designed to handle tests and provide accurate answers.\\n\\nTo confirm, would you like me to:\\n\\nA) Engage in a conversation on a specific topic\\nB) Ask you a question or request clarification on something\\nC) Practice providing responses to different types of questions\\nD) Something else (please specify)\\n\\nLet me know how I can assist you!\", 'options': None}]\n",
      "[{'role': 'user', 'metadata': None, 'content': 'test', 'options': None}, {'role': 'assistant', 'metadata': None, 'content': \"It looks like you're testing to see how I respond! Don't worry, I'm designed to handle tests and provide accurate answers.\\n\\nTo confirm, would you like me to:\\n\\nA) Engage in a conversation on a specific topic\\nB) Ask you a question or request clarification on something\\nC) Practice providing responses to different types of questions\\nD) Something else (please specify)\\n\\nLet me know how I can assist you!\", 'options': None}, {'role': 'user', 'metadata': None, 'content': 'what is the capital of france?', 'options': None}, {'role': 'assistant', 'metadata': None, 'content': 'Très facile!\\n\\nThe capital of France is Paris.', 'options': None}]\n"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(fn=assistant.stream, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cb6a52-9d3c-42f1-b127-303090c79a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_ollama(prompt, history=None):\n",
    "    if history != None:\n",
    "        messages = [{\"role\": \"system\", \"content\": SYSTEM_PROMPT}] + history + [{\"role\": \"user\", \"content\": prompt}]\n",
    "    else:\n",
    "        messages = [{\"role\": \"system\", \"content\": SYSTEM_PROMPT}] + [{\"role\": \"user\", \"content\": prompt}]\n",
    "    \n",
    "    # Start the streaming response\n",
    "    stream = ollama.chat(\n",
    "        model=MODEL,\n",
    "        messages=messages,\n",
    "        stream=True  # Make sure stream parameter is set to True\n",
    "    )\n",
    "    \n",
    "    # Stream each chunk as it arrives\n",
    "    response = \"\"\n",
    "    for chunk in stream:\n",
    "        if 'message' in chunk and chunk['message'].get('content'):\n",
    "            new_text = chunk['message']['content']\n",
    "            response += new_text\n",
    "            yield response  # With Gradio streaming, we yield the full response each time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4159a2fb-6a57-4de5-a0f1-5bd8b3612dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "view = gr.Interface(\n",
    "    fn=assistant.stream,\n",
    "    inputs=[gr.Textbox(label=\"Your message:\")],\n",
    "    outputs=[gr.Markdown(label=\"Response:\")],\n",
    "    flagging_mode=\"never\"\n",
    ")\n",
    "view.launch()  # You might want share=True for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c9d39e-743d-4f67-b258-bdfce3368745",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
